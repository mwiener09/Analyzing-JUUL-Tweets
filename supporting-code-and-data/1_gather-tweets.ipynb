{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'KwsM7g4X8QPXdGtAXpGf9zIVD'\n",
    "consumer_secret = 'mW6Ru1IxyyXGxIaFKL7YfWJC1dZWbHYWTA7bIdpMGqVL4hIBZd'\n",
    "access_token = '1055276480635265024-3HGLjEGA9wewgSuT9Pskio0Rhmr1H2'\n",
    "access_token_secret = '0e2lJBV2EHnMeOGm0QjE7X6SrX87ouDozANbdw8lDsRGo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heavily borrowed from \n",
    "# https://github.com/agalea91/twitter_search/blob/master/twitter_search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit = 1.5                           # runtime limit in hours\n",
    "max_tweets = 100                           # number of tweets per search (will be\n",
    "                                           # iterated over) - maximum is 100\n",
    "max_days_old = 8                           # search limits e.g., from 7 to 8\n",
    "                                           # gives current weekday from last week,\n",
    "                                           # min_days_old=0 will search from right now\n",
    "USA = '39.8,-95.583068847656,2500km'       # this geocode includes nearly all American\n",
    "                                           # states (and a large portion of Canada)\n",
    "query_list = [\"juul\",\"#Juul\",\"juuling\",\"#switchtojuul\"]\n",
    "#query_list = ['juuling','juul','#e-cigarettes', '#vape'] #'#switchtojuul','#juul', \n",
    "#read_IDs = False # initialize - first round of tweets added to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_search(api, query, max_tweets, max_id, since_id, geocode):\n",
    "    searched_tweets = []\n",
    "    while len(searched_tweets) < max_tweets:\n",
    "        remaining_tweets = max_tweets - len(searched_tweets)\n",
    "        try:\n",
    "            new_tweets = api.search(q = query, count = remaining_tweets,\\\n",
    "                               since_id = str(since_id), max_id = str(max_id-1),\\\n",
    "                                   geocode = geocode)\n",
    "            if not new_tweets: # does new_tweets have a value\n",
    "                print('no tweets found')\n",
    "                break\n",
    "            searched_tweets.extend(new_tweets) # adds new tweets\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError:\n",
    "            print('waiting 15 minutes due to time limit')\n",
    "            print(dt.datetime.now()+dt.timedelta(minutes=15))\n",
    "            time.sleep(15*60)\n",
    "            break       \n",
    "    return searched_tweets, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(query, day, max_id, since_id, time_limit, max_tweets, USA):\n",
    "    json_file = query.replace('#','hshtg_') + '_' + day + '.json'\n",
    "    print(json_file) \n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    start = dt.datetime.now()\n",
    "    end = start + dt.timedelta(hours=time_limit)\n",
    "    count, exitcount = 0, 0\n",
    "    while dt.datetime.now() < end:\n",
    "        count += 1\n",
    "        print('count =',count)\n",
    "        # collect tweets and update max_id\n",
    "        tweets, max_id = tweet_search(api=api, query=query, max_tweets=max_tweets,\n",
    "                                      max_id=max_id, since_id=since_id,\n",
    "                                      geocode=USA)\n",
    "        # write tweets to file in JSON format\n",
    "        if tweets:\n",
    "            with open(json_file, 'a') as f:\n",
    "                for tweet in tweets:\n",
    "                    json.dump(tweet._json, f)\n",
    "                    f.write('\\n')\n",
    "            exitcount = 0\n",
    "        else:\n",
    "            exitcount += 1\n",
    "            if exitcount == 3:\n",
    "                print('Maximum number of empty tweet strings reached - breaking')\n",
    "                break\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start date: \n",
      " 2018-11-18 18:12:02.727969\n",
      "start ID: \n",
      " 1063944536165101568\n",
      "end date: \n",
      " 2018-11-26 18:12:04.384909\n",
      "end ID: \n",
      " 1066843795352940544\n",
      "2018-11-18_to_2018-11-26\n",
      "juul_2018-11-18_to_2018-11-26.json\n",
      "count = 1\n",
      "count = 2\n",
      "count = 3\n",
      "count = 4\n",
      "count = 5\n",
      "count = 6\n",
      "count = 7\n",
      "count = 8\n",
      "count = 9\n",
      "count = 10\n",
      "count = 11\n",
      "count = 12\n",
      "count = 13\n",
      "count = 14\n",
      "count = 15\n",
      "count = 16\n",
      "count = 17\n",
      "count = 18\n",
      "count = 19\n",
      "count = 20\n",
      "count = 21\n",
      "count = 22\n",
      "count = 23\n",
      "no tweets found\n",
      "count = 24\n",
      "count = 25\n",
      "count = 26\n",
      "count = 27\n",
      "count = 28\n",
      "count = 29\n",
      "count = 30\n",
      "count = 31\n",
      "count = 32\n",
      "count = 33\n",
      "count = 34\n",
      "count = 35\n",
      "count = 36\n",
      "count = 37\n",
      "count = 38\n",
      "count = 39\n",
      "count = 40\n",
      "count = 41\n",
      "count = 42\n",
      "count = 43\n",
      "count = 44\n",
      "count = 45\n",
      "count = 46\n",
      "count = 47\n",
      "count = 48\n",
      "count = 49\n",
      "count = 50\n",
      "count = 51\n",
      "count = 52\n",
      "count = 53\n",
      "count = 54\n",
      "count = 55\n",
      "count = 56\n",
      "count = 57\n",
      "count = 58\n",
      "count = 59\n",
      "count = 60\n",
      "count = 61\n",
      "count = 62\n",
      "count = 63\n",
      "count = 64\n",
      "count = 65\n",
      "count = 66\n",
      "count = 67\n",
      "count = 68\n",
      "count = 69\n",
      "count = 70\n",
      "count = 71\n",
      "count = 72\n",
      "count = 73\n",
      "no tweets found\n",
      "count = 74\n",
      "count = 75\n",
      "count = 76\n",
      "count = 77\n",
      "no tweets found\n",
      "count = 78\n",
      "count = 79\n",
      "count = 80\n",
      "count = 81\n",
      "no tweets found\n",
      "count = 82\n",
      "count = 83\n",
      "count = 84\n",
      "count = 85\n",
      "count = 86\n",
      "count = 87\n",
      "count = 88\n",
      "count = 89\n",
      "count = 90\n",
      "no tweets found\n",
      "count = 91\n",
      "count = 92\n",
      "count = 93\n",
      "count = 94\n",
      "count = 95\n",
      "count = 96\n",
      "count = 97\n",
      "count = 98\n",
      "count = 99\n",
      "count = 100\n",
      "count = 101\n",
      "count = 102\n",
      "count = 103\n",
      "count = 104\n",
      "count = 105\n",
      "count = 106\n",
      "count = 107\n",
      "count = 108\n",
      "count = 109\n",
      "count = 110\n",
      "count = 111\n",
      "count = 112\n",
      "count = 113\n",
      "count = 114\n",
      "count = 115\n",
      "count = 116\n",
      "count = 117\n",
      "count = 118\n",
      "count = 119\n",
      "no tweets found\n",
      "count = 120\n",
      "no tweets found\n",
      "count = 121\n",
      "count = 122\n",
      "count = 123\n",
      "count = 124\n",
      "count = 125\n",
      "count = 126\n",
      "count = 127\n",
      "count = 128\n",
      "count = 129\n",
      "waiting 15 minutes due to time limit\n",
      "2018-11-26 18:29:33.034061\n",
      "count = 130\n",
      "count = 131\n",
      "count = 132\n",
      "count = 133\n",
      "count = 134\n",
      "count = 135\n",
      "count = 136\n",
      "count = 137\n",
      "count = 138\n",
      "count = 139\n",
      "count = 140\n",
      "count = 141\n",
      "count = 142\n",
      "count = 143\n",
      "count = 144\n",
      "count = 145\n",
      "count = 146\n",
      "count = 147\n",
      "count = 148\n",
      "count = 149\n",
      "count = 150\n",
      "count = 151\n",
      "count = 152\n",
      "count = 153\n",
      "count = 154\n",
      "count = 155\n",
      "count = 156\n",
      "count = 157\n",
      "count = 158\n",
      "count = 159\n",
      "count = 160\n",
      "count = 161\n",
      "count = 162\n",
      "count = 163\n",
      "count = 164\n",
      "count = 165\n",
      "count = 166\n",
      "count = 167\n",
      "count = 168\n",
      "count = 169\n",
      "count = 170\n",
      "count = 171\n",
      "count = 172\n",
      "count = 173\n",
      "count = 174\n",
      "count = 175\n",
      "count = 176\n",
      "count = 177\n",
      "count = 178\n",
      "count = 179\n",
      "count = 180\n",
      "count = 181\n",
      "count = 182\n",
      "count = 183\n",
      "count = 184\n",
      "count = 185\n",
      "count = 186\n",
      "count = 187\n",
      "count = 188\n",
      "count = 189\n",
      "count = 190\n",
      "count = 191\n",
      "count = 192\n",
      "count = 193\n",
      "count = 194\n",
      "count = 195\n",
      "count = 196\n",
      "count = 197\n",
      "count = 198\n",
      "count = 199\n",
      "count = 200\n",
      "count = 201\n",
      "count = 202\n",
      "count = 203\n",
      "count = 204\n",
      "count = 205\n",
      "count = 206\n",
      "count = 207\n",
      "count = 208\n",
      "count = 209\n",
      "count = 210\n",
      "count = 211\n",
      "count = 212\n",
      "count = 213\n",
      "count = 214\n",
      "count = 215\n",
      "count = 216\n",
      "count = 217\n",
      "count = 218\n",
      "count = 219\n",
      "count = 220\n",
      "count = 221\n",
      "count = 222\n",
      "count = 223\n",
      "count = 224\n",
      "count = 225\n",
      "count = 226\n",
      "count = 227\n",
      "count = 228\n",
      "count = 229\n",
      "count = 230\n",
      "count = 231\n",
      "count = 232\n",
      "count = 233\n",
      "count = 234\n",
      "count = 235\n",
      "count = 236\n",
      "count = 237\n",
      "count = 238\n",
      "count = 239\n",
      "count = 240\n",
      "count = 241\n",
      "count = 242\n",
      "count = 243\n",
      "count = 244\n",
      "count = 245\n",
      "count = 246\n",
      "count = 247\n",
      "count = 248\n",
      "count = 249\n",
      "count = 250\n",
      "count = 251\n",
      "count = 252\n",
      "count = 253\n",
      "count = 254\n",
      "count = 255\n",
      "count = 256\n",
      "count = 257\n",
      "count = 258\n",
      "count = 259\n",
      "count = 260\n",
      "count = 261\n",
      "count = 262\n",
      "count = 263\n",
      "count = 264\n",
      "count = 265\n",
      "count = 266\n",
      "count = 267\n",
      "count = 268\n",
      "count = 269\n",
      "count = 270\n",
      "count = 271\n",
      "count = 272\n",
      "count = 273\n",
      "count = 274\n",
      "count = 275\n",
      "count = 276\n",
      "count = 277\n",
      "count = 278\n",
      "count = 279\n",
      "count = 280\n",
      "count = 281\n",
      "count = 282\n",
      "count = 283\n",
      "count = 284\n",
      "count = 285\n",
      "count = 286\n",
      "count = 287\n",
      "count = 288\n",
      "count = 289\n",
      "count = 290\n",
      "count = 291\n",
      "count = 292\n",
      "count = 293\n",
      "count = 294\n",
      "count = 295\n",
      "count = 296\n",
      "count = 297\n",
      "count = 298\n",
      "count = 299\n",
      "count = 300\n",
      "count = 301\n",
      "count = 302\n",
      "count = 303\n",
      "count = 304\n",
      "waiting 15 minutes due to time limit\n",
      "2018-11-26 18:47:21.724328\n",
      "count = 305\n",
      "count = 306\n",
      "count = 307\n",
      "count = 308\n",
      "count = 309\n",
      "count = 310\n",
      "count = 311\n",
      "count = 312\n",
      "count = 313\n",
      "count = 314\n",
      "count = 315\n",
      "count = 316\n",
      "count = 317\n",
      "count = 318\n",
      "count = 319\n",
      "count = 320\n",
      "count = 321\n",
      "count = 322\n",
      "count = 323\n",
      "count = 324\n",
      "count = 325\n",
      "count = 326\n",
      "count = 327\n",
      "count = 328\n",
      "count = 329\n",
      "count = 330\n",
      "count = 331\n",
      "count = 332\n",
      "count = 333\n",
      "count = 334\n",
      "count = 335\n",
      "count = 336\n",
      "count = 337\n",
      "count = 338\n",
      "count = 339\n",
      "count = 340\n",
      "count = 341\n",
      "count = 342\n",
      "count = 343\n",
      "count = 344\n",
      "count = 345\n",
      "count = 346\n",
      "count = 347\n",
      "count = 348\n",
      "count = 349\n",
      "count = 350\n",
      "count = 351\n",
      "count = 352\n",
      "count = 353\n",
      "count = 354\n",
      "count = 355\n",
      "count = 356\n",
      "count = 357\n",
      "count = 358\n",
      "count = 359\n",
      "count = 360\n",
      "count = 361\n",
      "count = 362\n",
      "count = 363\n",
      "count = 364\n",
      "count = 365\n",
      "count = 366\n",
      "count = 367\n",
      "count = 368\n",
      "count = 369\n",
      "count = 370\n",
      "count = 371\n",
      "count = 372\n",
      "count = 373\n",
      "count = 374\n",
      "count = 375\n",
      "count = 376\n",
      "count = 377\n",
      "count = 378\n",
      "count = 379\n",
      "count = 380\n",
      "count = 381\n",
      "count = 382\n",
      "count = 383\n",
      "count = 384\n",
      "count = 385\n",
      "count = 386\n",
      "count = 387\n",
      "count = 388\n",
      "count = 389\n",
      "count = 390\n",
      "count = 391\n",
      "count = 392\n",
      "count = 393\n",
      "count = 394\n",
      "count = 395\n",
      "count = 396\n",
      "count = 397\n",
      "count = 398\n",
      "count = 399\n",
      "count = 400\n",
      "count = 401\n",
      "count = 402\n",
      "count = 403\n",
      "count = 404\n",
      "count = 405\n",
      "count = 406\n",
      "count = 407\n",
      "count = 408\n",
      "count = 409\n",
      "count = 410\n",
      "count = 411\n",
      "count = 412\n",
      "count = 413\n",
      "count = 414\n",
      "count = 415\n",
      "count = 416\n",
      "count = 417\n",
      "count = 418\n",
      "count = 419\n",
      "count = 420\n",
      "count = 421\n",
      "count = 422\n",
      "count = 423\n",
      "count = 424\n",
      "count = 425\n",
      "count = 426\n",
      "count = 427\n",
      "count = 428\n",
      "count = 429\n",
      "count = 430\n",
      "count = 431\n",
      "count = 432\n",
      "count = 433\n",
      "count = 434\n",
      "count = 435\n",
      "count = 436\n",
      "count = 437\n",
      "count = 438\n",
      "count = 439\n",
      "count = 440\n",
      "count = 441\n",
      "count = 442\n",
      "count = 443\n",
      "count = 444\n",
      "count = 445\n",
      "count = 446\n",
      "count = 447\n",
      "count = 448\n",
      "count = 449\n",
      "count = 450\n",
      "count = 451\n",
      "count = 452\n",
      "count = 453\n",
      "count = 454\n",
      "count = 455\n",
      "count = 456\n",
      "count = 457\n",
      "count = 458\n",
      "count = 459\n",
      "count = 460\n",
      "count = 461\n",
      "count = 462\n",
      "count = 463\n",
      "count = 464\n",
      "count = 465\n",
      "count = 466\n",
      "count = 467\n",
      "count = 468\n",
      "count = 469\n",
      "count = 470\n",
      "count = 471\n",
      "count = 472\n",
      "count = 473\n",
      "count = 474\n",
      "count = 475\n",
      "count = 476\n",
      "count = 477\n",
      "count = 478\n",
      "count = 479\n",
      "count = 480\n",
      "count = 481\n",
      "count = 482\n",
      "count = 483\n",
      "count = 484\n",
      "count = 485\n",
      "waiting 15 minutes due to time limit\n",
      "2018-11-26 19:05:12.836858\n",
      "count = 486\n",
      "count = 487\n",
      "count = 488\n",
      "count = 489\n",
      "count = 490\n",
      "count = 491\n",
      "count = 492\n",
      "count = 493\n",
      "count = 494\n",
      "count = 495\n",
      "count = 496\n",
      "count = 497\n",
      "count = 498\n",
      "count = 499\n",
      "count = 500\n",
      "count = 501\n",
      "count = 502\n",
      "count = 503\n",
      "count = 504\n",
      "count = 505\n",
      "count = 506\n",
      "count = 507\n",
      "count = 508\n",
      "count = 509\n",
      "count = 510\n",
      "count = 511\n",
      "count = 512\n",
      "count = 513\n",
      "count = 514\n",
      "count = 515\n",
      "count = 516\n",
      "count = 517\n",
      "count = 518\n",
      "count = 519\n",
      "count = 520\n",
      "count = 521\n",
      "count = 522\n",
      "count = 523\n",
      "count = 524\n",
      "count = 525\n",
      "count = 526\n",
      "count = 527\n",
      "count = 528\n",
      "count = 529\n",
      "count = 530\n",
      "count = 531\n",
      "count = 532\n",
      "count = 533\n",
      "count = 534\n",
      "no tweets found\n",
      "count = 535\n",
      "no tweets found\n",
      "count = 536\n",
      "no tweets found\n",
      "count = 537\n",
      "no tweets found\n",
      "Maximum number of empty tweet strings reached - breaking\n",
      "finished with query: juul\n",
      "file: juul_2018-11-18_to_2018-11-26.json\n",
      "start date: \n",
      " 2018-11-18 19:06:04.029580\n",
      "start ID: \n",
      " 1063937983831670784\n",
      "end date: \n",
      " 2018-11-26 19:06:04.331589\n",
      "end ID: \n",
      " 1066813574155247619\n",
      "2018-11-18_to_2018-11-26\n",
      "hshtg_Juul_2018-11-18_to_2018-11-26.json\n",
      "count = 1\n",
      "count = 2\n",
      "no tweets found\n",
      "count = 3\n",
      "no tweets found\n",
      "count = 4\n",
      "no tweets found\n",
      "count = 5\n",
      "no tweets found\n",
      "Maximum number of empty tweet strings reached - breaking\n",
      "finished with query: #Juul\n",
      "file: hshtg_Juul_2018-11-18_to_2018-11-26.json\n",
      "start date: \n",
      " 2018-11-18 19:06:08.054227\n",
      "start ID: \n",
      " 1063943376687546368\n",
      "end date: \n",
      " 2018-11-26 19:06:08.335690\n",
      "end ID: \n",
      " 1066843686745645057\n",
      "2018-11-18_to_2018-11-26\n",
      "juuling_2018-11-18_to_2018-11-26.json\n",
      "count = 1\n",
      "count = 2\n",
      "count = 3\n",
      "count = 4\n",
      "count = 5\n",
      "count = 6\n",
      "count = 7\n",
      "count = 8\n",
      "count = 9\n",
      "no tweets found\n",
      "count = 10\n",
      "no tweets found\n",
      "count = 11\n",
      "no tweets found\n",
      "count = 12\n",
      "no tweets found\n",
      "count = 13\n",
      "no tweets found\n",
      "Maximum number of empty tweet strings reached - breaking\n",
      "finished with query: juuling\n",
      "file: juuling_2018-11-18_to_2018-11-26.json\n",
      "start date: \n",
      " 2018-11-18 19:06:19.435165\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-66e99b6c10c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# get list of up to 10 tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtweet_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtweet_date_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeocode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mUSA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msince_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'start ID:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msince_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for q in query_list:\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    d1 = dt.datetime.now() - dt.timedelta(days=max_days_old)\n",
    "    print('start date:','\\n',d1)\n",
    "    tweet_date_1 = '{0}-{1:0>2}-{2:0>2}'.format(d1.year, d1.month, d1.day)\n",
    "    # get list of up to 10 tweets\n",
    "    tweet_1 = api.search(q=q, count=1, until=tweet_date_1, geocode=USA)\n",
    "    since_id = tweet_1[0].id\n",
    "    print('start ID:','\\n',since_id)\n",
    "\n",
    "    d2 = dt.datetime.now() # if someone didnt tweet\n",
    "    print('end date:','\\n',d2)\n",
    "    tweet_date_2 = '{0}-{1:0>2}-{2:0>2}'.format(d2.year, d2.month, d2.day)\n",
    "    # get list of up to 10 tweets\n",
    "    tweet_2 = api.search(q=q, count=10, until=tweet_date_2, geocode=USA)\n",
    "    max_id = tweet_2[0].id\n",
    "    print('end ID:','\\n',max_id)\n",
    "\n",
    "    day = '{0}-{1:0>2}-{2:0>2}_to_{3}-{4:0>2}-{5:0>2}'.format(\n",
    "           d1.year, d1.month, d1.day, d2.year, d2.month, d2.day)\n",
    "    print(day)\n",
    "    \n",
    "    json_file = scrape_tweets(query=q, day=day,max_id=max_id, since_id=since_id,time_limit=1.5, max_tweets=max_tweets, USA=USA)\n",
    "    print('finished with query:',q)\n",
    "    print('file:',json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file = 'juul_2018-10-20_to_2018-10-28.json'\n",
    "# tweet_data = []\n",
    "# with open(json_file, 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         tweet_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "\n",
    "# #general info\n",
    "# df['id'] = list(map(lambda tweet: tweet['id_str'], tweet_data))\n",
    "# df['tweet_date'] = list(map(lambda tweet: tweet['created_at'], tweet_data))\n",
    "# df['text'] = list(map(lambda tweet: tweet['text'], tweet_data))\n",
    "# df['lang'] = list(map(lambda tweet: tweet['lang'], tweet_data))\n",
    "# # user information\n",
    "# df['location'] = list(map(lambda tweet: tweet['user']['location'], tweet_data))\n",
    "# df['protected'] = list(map(lambda tweet: tweet['user']['protected'], tweet_data))\n",
    "# df['profile_description'] = list(map(lambda tweet: tweet['user']['description'], tweet_data))\n",
    "# df['followers_count'] = list(map(lambda tweet: tweet['user']['followers_count'], tweet_data))\n",
    "# df['friends_count'] = list(map(lambda tweet: tweet['user']['friends_count'], tweet_data))\n",
    "# df['listed_count'] = list(map(lambda tweet: tweet['user']['listed_count'], tweet_data))\n",
    "# df['favourites_count'] = list(map(lambda tweet: tweet['user']['favourites_count'], tweet_data))\n",
    "# df['geo_enabled'] = list(map(lambda tweet: tweet['user']['geo_enabled'], tweet_data))\n",
    "# df['verified'] = list(map(lambda tweet: tweet['user']['verified'], tweet_data))\n",
    "# df['statuses_count'] = list(map(lambda tweet: tweet['user']['statuses_count'], tweet_data))\n",
    "# # tweet info\n",
    "# df['retweet_count'] = list(map(lambda tweet: tweet['retweet_count'], tweet_data))\n",
    "# df['favorite_count'] = list(map(lambda tweet: tweet['favorite_count'], tweet_data))\n",
    "# df['favorited'] = list(map(lambda tweet: tweet['favorited'], tweet_data))\n",
    "# df['retweeted'] = list(map(lambda tweet: tweet['retweeted'], tweet_data))\n",
    "# # tweet location\n",
    "# df['longitude'] = list(map(lambda tweet: tweet['coordinates']['coordinates'][0] \n",
    "#                                   if tweet['coordinates'] != None else 'NaN', tweet_data))\n",
    "# df['latitude'] = list(map(lambda tweet: tweet['coordinates']['coordinates'][1] \n",
    "#                                   if tweet['coordinates'] != None else 'NaN', tweet_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>protected</th>\n",
       "      <th>profile_description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056334344787292160</td>\n",
       "      <td>Sat Oct 27 23:58:28 +0000 2018</td>\n",
       "      <td>RT @Sadieisonfire: do u enjoy the crack of a w...</td>\n",
       "      <td>en</td>\n",
       "      <td>66.6 FM</td>\n",
       "      <td>False</td>\n",
       "      <td>emo • your fav bio exorcist • Joseph 💜💜 • G59 ...</td>\n",
       "      <td>464</td>\n",
       "      <td>421</td>\n",
       "      <td>2</td>\n",
       "      <td>3124</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>23049</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056334344128733185</td>\n",
       "      <td>Sat Oct 27 23:58:28 +0000 2018</td>\n",
       "      <td>Can’t rlly think of anything more tragic than ...</td>\n",
       "      <td>en</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>False</td>\n",
       "      <td>A place for my thots bcuz my friends are sick ...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056334201572605952</td>\n",
       "      <td>Sat Oct 27 23:57:54 +0000 2018</td>\n",
       "      <td>RT @ItsJohnConner: @nytimes They lost to Juul ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Calgary, Alberta</td>\n",
       "      <td>False</td>\n",
       "      <td>vaper 4yrs +/non-smoker/just a mom/volunteer 4...</td>\n",
       "      <td>358</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>17364</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12763</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056334169419251712</td>\n",
       "      <td>Sat Oct 27 23:57:46 +0000 2018</td>\n",
       "      <td>RT @Sadieisonfire: do u enjoy the crack of a w...</td>\n",
       "      <td>en</td>\n",
       "      <td>st. augustine, fl</td>\n",
       "      <td>False</td>\n",
       "      <td>beyond happy</td>\n",
       "      <td>458</td>\n",
       "      <td>441</td>\n",
       "      <td>2</td>\n",
       "      <td>13460</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3776</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056334111772684290</td>\n",
       "      <td>Sat Oct 27 23:57:32 +0000 2018</td>\n",
       "      <td>Rip to my 9th juul onto my 10th #ripbankaccoun...</td>\n",
       "      <td>en</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>False</td>\n",
       "      <td>straight chillin</td>\n",
       "      <td>328</td>\n",
       "      <td>189</td>\n",
       "      <td>3</td>\n",
       "      <td>9240</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8353</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                      tweet_date  \\\n",
       "0  1056334344787292160  Sat Oct 27 23:58:28 +0000 2018   \n",
       "1  1056334344128733185  Sat Oct 27 23:58:28 +0000 2018   \n",
       "2  1056334201572605952  Sat Oct 27 23:57:54 +0000 2018   \n",
       "3  1056334169419251712  Sat Oct 27 23:57:46 +0000 2018   \n",
       "4  1056334111772684290  Sat Oct 27 23:57:32 +0000 2018   \n",
       "\n",
       "                                                text lang           location  \\\n",
       "0  RT @Sadieisonfire: do u enjoy the crack of a w...   en            66.6 FM   \n",
       "1  Can’t rlly think of anything more tragic than ...   en       New York, NY   \n",
       "2  RT @ItsJohnConner: @nytimes They lost to Juul ...   en   Calgary, Alberta   \n",
       "3  RT @Sadieisonfire: do u enjoy the crack of a w...   en  st. augustine, fl   \n",
       "4  Rip to my 9th juul onto my 10th #ripbankaccoun...   en        Chicago, IL   \n",
       "\n",
       "   protected                                profile_description  \\\n",
       "0      False  emo • your fav bio exorcist • Joseph 💜💜 • G59 ...   \n",
       "1      False  A place for my thots bcuz my friends are sick ...   \n",
       "2      False  vaper 4yrs +/non-smoker/just a mom/volunteer 4...   \n",
       "3      False                                       beyond happy   \n",
       "4      False                                   straight chillin   \n",
       "\n",
       "   followers_count  friends_count  listed_count  favourites_count  \\\n",
       "0              464            421             2              3124   \n",
       "1                5             10             0               118   \n",
       "2              358            287             5             17364   \n",
       "3              458            441             2             13460   \n",
       "4              328            189             3              9240   \n",
       "\n",
       "   geo_enabled  verified  statuses_count  retweet_count  favorite_count  \\\n",
       "0         True     False           23049            670               0   \n",
       "1        False     False             314              0               0   \n",
       "2        False     False           12763              4               0   \n",
       "3        False     False            3776            670               0   \n",
       "4         True     False            8353              0               3   \n",
       "\n",
       "   favorited  retweeted longitude latitude  \n",
       "0      False      False       NaN      NaN  \n",
       "1      False      False       NaN      NaN  \n",
       "2      False      False       NaN      NaN  \n",
       "3      False      False       NaN      NaN  \n",
       "4      False      False       NaN      NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
